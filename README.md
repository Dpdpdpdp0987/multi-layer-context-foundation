# Multi-Layer Context Foundation System

![License](https://img.shields.io/badge/license-MIT-blue.svg)
![Python](https://img.shields.io/badge/python-3.10%2B-blue.svg)
![Status](https://img.shields.io/badge/status-alpha-orange.svg)

An advanced multi-layer context management system with hybrid retrieval capabilities for AI assistants. This system combines semantic memory, vector search, knowledge graphs, and adaptive context routing to provide intelligent, context-aware responses.

## ğŸ¯ Overview

The Multi-Layer Context Foundation addresses the challenge of maintaining coherent, relevant context across extended AI conversations by implementing:

- **Multi-Layer Memory Architecture**: Short-term, working, and long-term memory layers
- **Hybrid Retrieval System**: Combines vector search, keyword matching, and graph-based retrieval
- **Adaptive Context Management**: Dynamic context window optimization
- **Semantic Knowledge Storage**: Vector embeddings with relationship mapping
- **MCP Server Integration**: Compatible with Model Context Protocol

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Application Layer                        â”‚
â”‚                  (MCP Server / API Gateway)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Context Manager (Core)                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Short    â”‚  â”‚  Working   â”‚  â”‚    Long-Term        â”‚   â”‚
â”‚  â”‚   Term     â”‚â”€â–¶â”‚  Memory    â”‚â”€â–¶â”‚    Memory           â”‚   â”‚
â”‚  â”‚  Memory    â”‚  â”‚            â”‚  â”‚  (Vector + Graph)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Hybrid Retrieval Engine                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   Vector    â”‚  â”‚   Keyword    â”‚  â”‚     Graph        â”‚   â”‚
â”‚  â”‚   Search    â”‚  â”‚    Search    â”‚  â”‚   Traversal      â”‚   â”‚
â”‚  â”‚  (Semantic) â”‚  â”‚    (BM25)    â”‚  â”‚  (Relations)     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Storage Layer                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   Vector DB  â”‚  â”‚   Graph DB   â”‚  â”‚   Document DB    â”‚  â”‚
â”‚  â”‚  (Qdrant/    â”‚  â”‚   (Neo4j/    â”‚  â”‚   (SQLite/       â”‚  â”‚
â”‚  â”‚   Milvus)    â”‚  â”‚   LibSQL)    â”‚  â”‚   PostgreSQL)    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Features

### Core Capabilities

- **Intelligent Memory Hierarchy**
  - Short-term: Recent conversation context (last 5-10 exchanges)
  - Working memory: Active task context with relevance scoring
  - Long-term: Persistent knowledge with semantic indexing

- **Hybrid Retrieval**
  - Semantic search using vector embeddings
  - Keyword-based BM25 ranking
  - Graph-based relationship traversal
  - Intelligent result fusion and re-ranking

- **Context Optimization**
  - Dynamic context window management
  - Relevance-based pruning
  - Token budget optimization
  - Mode-aware context adaptation

- **Knowledge Management**
  - Automatic entity extraction
  - Relationship mapping
  - Conflict resolution
  - Version tracking

## ğŸ“‹ Prerequisites

- Python 3.10 or higher
- Docker (optional, for containerized deployment)
- 4GB+ RAM recommended
- Storage: 1GB+ for vector databases

## ğŸ”§ Installation

### Quick Start

```bash
# Clone the repository
git clone https://github.com/Dpdpdpdp0987/multi-layer-context-foundation.git
cd multi-layer-context-foundation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run setup script
python scripts/setup.py

# Initialize databases
python scripts/init_databases.py
```

### Docker Installation

```bash
# Build the image
docker-compose build

# Start services
docker-compose up -d

# Check status
docker-compose ps
```

## ğŸ“– Usage

### Basic Usage

```python
from mlcf import ContextManager, HybridRetriever

# Initialize the context manager
context_mgr = ContextManager(
    vector_db="qdrant",
    graph_db="neo4j",
    embedding_model="sentence-transformers/all-MiniLM-L6-v2"
)

# Store information
context_mgr.store(
    content="User prefers Python for backend development",
    metadata={"type": "preference", "category": "programming"}
)

# Retrieve relevant context
context = context_mgr.retrieve(
    query="What programming language should I use?",
    max_results=5,
    strategy="hybrid"  # or "semantic", "keyword", "graph"
)

print(context)
```

### MCP Server Mode

```bash
# Start MCP server
python -m mlcf.server --port 3000

# Or use the CLI
mlcf serve --config config/mcp_config.yaml
```

### Configuration

Create a `config.yaml` file:

```yaml
memory:
  short_term:
    max_size: 10
    retention_policy: "fifo"
  
  working:
    max_size: 50
    relevance_threshold: 0.7
  
  long_term:
    vector_db:
      provider: "qdrant"
      host: "localhost"
      port: 6333
    graph_db:
      provider: "neo4j"
      uri: "bolt://localhost:7687"

retrieval:
  strategy: "hybrid"
  weights:
    semantic: 0.5
    keyword: 0.3
    graph: 0.2
  
  reranking:
    enabled: true
    model: "cross-encoder/ms-marco-MiniLM-L-6-v2"

embeddings:
  model: "sentence-transformers/all-MiniLM-L6-v2"
  dimension: 384
  batch_size: 32
```

## ğŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run specific test suite
pytest tests/test_context_manager.py -v

# Run with coverage
pytest --cov=mlcf tests/

# Run integration tests
pytest tests/integration/ --slow
```

## ğŸ“Š Performance

- **Query Latency**: <100ms for semantic search (avg)
- **Throughput**: 100+ queries/second
- **Memory Footprint**: ~500MB baseline
- **Scalability**: Tested with 1M+ documents

## ğŸ—ºï¸ Roadmap

- [x] Core memory architecture
- [x] Basic vector search
- [ ] Graph database integration
- [ ] Hybrid retrieval with re-ranking
- [ ] MCP server implementation
- [ ] Adaptive context optimization
- [ ] Multi-modal support (images, audio)
- [ ] Distributed deployment support
- [ ] Real-time streaming updates
- [ ] Advanced conflict resolution

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for details.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Inspired by [BondAI](https://github.com/krohling/bondai) and [Context-Keeper](https://github.com/redleaves/context-keeper)
- Built on top of LangChain, Qdrant, and Neo4j
- Special thanks to the MCP community

## ğŸ“§ Contact

- GitHub: [@Dpdpdpdp0987](https://github.com/Dpdpdpdp0987)
- Issues: [GitHub Issues](https://github.com/Dpdpdpdp0987/multi-layer-context-foundation/issues)

## ğŸ“š Documentation

For detailed documentation, visit our [Wiki](https://github.com/Dpdpdpdp0987/multi-layer-context-foundation/wiki) or check the [docs/](docs/) directory.

---

**Status**: Alpha - Under active development

**Last Updated**: January 2026